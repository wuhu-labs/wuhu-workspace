---
title: "Compaction never triggers for Anthropic models"
status: done
assignee: agent
priority: critical
---

# WUHU-0043: Compaction never triggers for Anthropic models

## Priority: Critical

## Summary

Compaction is completely broken for Anthropic models because the agent loop
gates the compaction check on `message.usage` being non-nil, but the Anthropic
provider never populates that field. This means Anthropic sessions grow
unbounded until they hit the 200K token limit and fail with HTTP 400.

## Root Cause

In `AgentLoop.swift` (line ~187):

```swift
// Compaction
if let usage = message.usage,
   behavior.shouldCompact(state: state, usage: usage)
{
    try await behavior.performCompaction(state: state)
}
```

The `if let usage = message.usage` guard requires `usage` to be non-nil.
However, only the OpenAI providers (`OpenAIResponsesProvider`,
`OpenAICodexResponsesProvider`) parse and set `AssistantMessage.usage`.
The `AnthropicMessagesProvider` never sets it — it's always `nil`.

So for every Anthropic API call, the compaction check is silently skipped.

## Evidence

Session `f2cb7d4f-c34a-409e-8b1e-4e441c564dd9` ("Multi modality") using
`claude-opus-4-6`:

- 866 API calls, context grew monotonically from 1 → 1742 messages
- Zero compaction events across the entire session
- Eventually hit `prompt is too long: 200017 tokens > 200000 maximum`
- Session became unresponsive — user could not interact with it

The server log shows:
```
[WuhuSessionRuntime] loop.start() failed for session 'f2cb7d4f-...':
HTTP 400: {"type":"error","error":{"type":"invalid_request_error",
"message":"prompt is too long: 200017 tokens > 200000 maximum"}}
```

## Fix

Two options (both should probably be done):

### Option A: Don't gate compaction on usage (quick fix)

`shouldCompact` in `WuhuSessionBehavior` already does its own token estimation
from the message history — it doesn't use the `usage` parameter at all (it's
`usage _: Usage`). So the `usage` value is never needed. The guard can be
removed:

```swift
// Before:
if let usage = message.usage,
   behavior.shouldCompact(state: state, usage: usage) { ... }

// After:
if behavior.shouldCompact(state: state) { ... }
```

And update the `shouldCompact` protocol method to drop the `usage` parameter
since it's unused.

### Option B: Parse usage from Anthropic SSE (proper fix)

The Anthropic Messages API returns usage in the `message_delta` SSE event:

```json
{"type": "message_delta", "usage": {"output_tokens": 42},
 "delta": {"stop_reason": "end_turn"}}
```

And the initial `message_start` event contains:

```json
{"type": "message_start", "message": {"usage": {"input_tokens": 1234, "output_tokens": 0}}}
```

Parse these in `AnthropicMessagesProvider` and populate
`AssistantMessage.usage`. This also benefits logging, cost tracking, and any
future usage-based logic.

## Related

This bug was discovered during investigation of session `f2cb7d4f` where the
model also entered a degenerate polling loop (765 consecutive
`list_child_sessions` calls). The polling loop is a separate problem, but
compaction should have prevented the context from hitting the hard limit
regardless.

## Affected Components

- `wuhu-core`: `AgentLoop.swift` (compaction gate)
- `wuhu-core`: `AgentLoopContracts.swift` (protocol signature)
- `wuhu-core`: `WuhuSessionBehavior.swift` (shouldCompact signature)
- `wuhu-ai`: `AnthropicMessagesProvider.swift` (missing usage parsing)
