# WUHU-0034: Add support for 1M context Claude Opus 4.6

## Status: Done

## Summary

Add support for Claude Opus 4.6 with 1M token context window via a fake model alias `claude-opus-4-6[1m]`. This alias resolves to the real `claude-opus-4-6` API model ID but applies the `context-1m-2025-08-07` anthropic-beta header. Also add the Sonnet 4.6 1M variant since it uses the same mechanism.

Update compaction settings to use the model spec's `maxInputTokens` for context window size, so 1M models don't compact too aggressively at the 200K default threshold.

## Changes

1. **WuhuModelCatalog**: Add `ResolvedModelAlias` struct, `resolveAlias()` function, 1M spec entries, and 1M model options to the Anthropic model list.
2. **WuhuCompactionSettings**: Use model spec's `maxInputTokens` for context window (instead of hardcoded per-provider default). Scale `keepRecentTokens` proportionally.
3. **WuhuSessionBehavior**: Resolve model alias before API calls in `infer()` and `performCompaction()`. Merge beta headers into request options.
4. **Tests**: Update model catalog tests for new entries and add alias resolution tests.

## References

- Anthropic docs: 1M context window requires `anthropic-beta: context-1m-2025-08-07` header
- Claude Opus 4.6: 1M input tokens, 128K max output tokens
- Claude Sonnet 4.6: 1M input tokens, 64K max output tokens
